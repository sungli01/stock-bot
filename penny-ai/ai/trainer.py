"""
Penny Stock AI Trainer
- PPO ì•Œê³ ë¦¬ì¦˜ (stable-baselines3)
- í•™ìŠµ/ê²€ì¦ ê¸°ê°„ ë¶„ë¦¬ (ê³¼ì í•© ë°©ì§€)
- S3ì—ì„œ ë°ì´í„° ë¡œë“œ â†’ í•™ìŠµ â†’ S3ì— ëª¨ë¸ ì €ì¥
"""
import os
import sys
import io
import logging
import boto3
import pandas as pd
import numpy as np
import requests
from datetime import datetime
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize
from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback
from stable_baselines3.common.monitor import Monitor

# ê²½ë¡œ ì„¤ì • (Colab í™˜ê²½ ëŒ€ì‘)
_BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if _BASE_DIR not in sys.path:
    sys.path.insert(0, _BASE_DIR)

from processor.feature_engine import build_features, FEATURE_COLS
from ai.environment import PennyStockEnv

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')
logger = logging.getLogger(__name__)

# S3 ì„¤ì •
S3_BUCKET = 'sungli-market-data'
S3_INTRADAY_PREFIX = 'raw/intraday/'
S3_MODEL_PREFIX = 'penny-ai/models/'
REGION = 'ap-northeast-2'

# í•™ìŠµ/ê²€ì¦ ê¸°ê°„ ë¶„ë¦¬
TRAIN_START = '2025-01-01'
TRAIN_END = '2025-09-30'
VALID_START = '2025-10-01'
VALID_END = '2025-12-31'

# í…”ë ˆê·¸ë¨ ì•Œë¦¼
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_BOT_TOKEN', '')
TELEGRAM_CHAT_ID = os.environ.get('TELEGRAM_CHAT_ID', '5810895605')

# í•™ìŠµ ëŒ€ìƒ ì¢…ëª©
TICKERS = ['SOXL', 'TQQQ', 'SPXL', 'FNGU', 'LABU',
           'SOXS', 'SQQQ', 'SPXS', 'FNGD', 'LABD']


def send_telegram(msg: str):
    if not TELEGRAM_TOKEN:
        logger.info(f"[Telegram] {msg}")
        return
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        requests.post(url, json={'chat_id': TELEGRAM_CHAT_ID, 'text': msg}, timeout=10)
    except Exception as e:
        logger.warning(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")


def load_s3_data(s3_client, ticker: str, start: str, end: str, session_type: str = 'reg') -> pd.DataFrame:
    """S3ì—ì„œ íŠ¹ì • í‹°ì»¤ì˜ 1ë¶„ë´‰ ë°ì´í„° ë¡œë“œ"""
    frames = []
    paginator = s3_client.get_paginator('list_objects_v2')

    for page in paginator.paginate(Bucket=S3_BUCKET, Prefix=S3_INTRADAY_PREFIX):
        for obj in page.get('Contents', []):
            key = obj['Key']
            # ë‚ ì§œ íŒŒì‹±
            parts = key.split('/')
            if len(parts) < 4:
                continue
            date_str = parts[2]  # raw/intraday/2025-01-02/
            if date_str < start or date_str > end:
                continue
            filename = parts[-1]
            if not filename.startswith(ticker) or f'_{session_type}_1m.parquet' not in filename:
                continue

            try:
                obj_data = s3_client.get_object(Bucket=S3_BUCKET, Key=key)
                df = pd.read_parquet(io.BytesIO(obj_data['Body'].read()))
                df['date'] = date_str
                frames.append(df)
            except Exception as e:
                logger.warning(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {key}: {e}")

    if not frames:
        return pd.DataFrame()

    combined = pd.concat(frames, ignore_index=True)
    combined.sort_index(inplace=True)
    return combined


def prepare_env(df: pd.DataFrame, window_size: int = 30):
    df_feat = build_features(df)
    env = PennyStockEnv(df_feat, window_size=window_size)
    env = Monitor(env)
    return DummyVecEnv([lambda: env])


def train():
    logger.info("ğŸš€ í˜ë‹ˆìŠ¤íƒ AI í•™ìŠµ ì‹œì‘!")
    send_telegram("ğŸš€ í˜ë‹ˆìŠ¤íƒ AI í•™ìŠµ ì‹œì‘!\ní•™ìŠµ ê¸°ê°„: 2025-01-01 ~ 2025-09-30")

    s3 = boto3.client('s3', region_name=REGION)

    all_train_frames = []
    all_valid_frames = []

    for ticker in TICKERS:
        logger.info(f"ğŸ“¥ {ticker} ë°ì´í„° ë¡œë“œ ì¤‘...")
        train_df = load_s3_data(s3, ticker, TRAIN_START, TRAIN_END, 'reg')
        valid_df = load_s3_data(s3, ticker, VALID_START, VALID_END, 'reg')

        if not train_df.empty:
            train_df['ticker'] = ticker
            all_train_frames.append(train_df)
            logger.info(f"  {ticker} í•™ìŠµ ë°ì´í„°: {len(train_df)}í–‰")
        if not valid_df.empty:
            valid_df['ticker'] = ticker
            all_valid_frames.append(valid_df)
            logger.info(f"  {ticker} ê²€ì¦ ë°ì´í„°: {len(valid_df)}í–‰")

    if not all_train_frames:
        logger.error("âŒ í•™ìŠµ ë°ì´í„° ì—†ìŒ!")
        send_telegram("âŒ í•™ìŠµ ë°ì´í„° ì—†ìŒ! ìˆ˜ì§‘ ìƒíƒœ í™•ì¸ í•„ìš”")
        return

    train_df = pd.concat(all_train_frames, ignore_index=True)
    valid_df = pd.concat(all_valid_frames, ignore_index=True) if all_valid_frames else None

    logger.info(f"âœ… í•™ìŠµ ë°ì´í„° ì´ {len(train_df)}í–‰ ë¡œë“œ ì™„ë£Œ")

    # í™˜ê²½ ìƒì„±
    train_env = prepare_env(train_df)
    train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True)

    # PPO ëª¨ë¸ ìƒì„±
    model = PPO(
        'MlpPolicy',
        train_env,
        learning_rate=3e-4,
        n_steps=2048,
        batch_size=64,
        n_epochs=10,
        gamma=0.99,
        gae_lambda=0.95,
        clip_range=0.2,
        ent_coef=0.01,
        verbose=1,
        tensorboard_log='/tmp/penny_ai_tb/'
    )

    # ì½œë°±
    callbacks = []

    if valid_df is not None and not valid_df.empty:
        valid_env = prepare_env(valid_df)
        valid_env = VecNormalize(valid_env, norm_obs=True, norm_reward=False, training=False)
        eval_cb = EvalCallback(
            valid_env,
            best_model_save_path='/tmp/penny_ai_best/',
            log_path='/tmp/penny_ai_eval/',
            eval_freq=10000,
            deterministic=True,
            verbose=1
        )
        callbacks.append(eval_cb)

    checkpoint_cb = CheckpointCallback(
        save_freq=50000,
        save_path='/tmp/penny_ai_checkpoints/',
        name_prefix='ppo_penny'
    )
    callbacks.append(checkpoint_cb)

    # í•™ìŠµ ì‹¤í–‰
    total_timesteps = 500_000
    logger.info(f"ğŸ¤– PPO í•™ìŠµ ì‹œì‘ (ì´ {total_timesteps:,} ìŠ¤í…)")
    send_telegram(f"ğŸ¤– PPO í•™ìŠµ ì¤‘...\nì´ {total_timesteps:,} ìŠ¤í…\nì˜ˆìƒ ì™„ë£Œ: ì•½ 20~30ë¶„")

    model.learn(
        total_timesteps=total_timesteps,
        callback=callbacks,
        progress_bar=True
    )

    # ëª¨ë¸ S3 ì €ì¥
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    model_path = f'/tmp/ppo_penny_{timestamp}'
    model.save(model_path)
    train_env.save(f'{model_path}_vecnorm.pkl')

    # S3 ì—…ë¡œë“œ
    model_key = f"{S3_MODEL_PREFIX}ppo_penny_{timestamp}.zip"
    s3.upload_file(f'{model_path}.zip', S3_BUCKET, model_key)
    logger.info(f"âœ… ëª¨ë¸ S3 ì €ì¥ ì™„ë£Œ: {model_key}")

    send_telegram(
        f"âœ… í˜ë‹ˆìŠ¤íƒ AI í•™ìŠµ ì™„ë£Œ!\n"
        f"ëª¨ë¸: {model_key}\n"
        f"í•™ìŠµ ê¸°ê°„: {TRAIN_START} ~ {TRAIN_END}\n"
        f"ì´ ìŠ¤í…: {total_timesteps:,}\n"
        f"â†’ ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹œì‘ ì¤€ë¹„ ì™„ë£Œ!"
    )

    logger.info("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")


if __name__ == '__main__':
    train()
